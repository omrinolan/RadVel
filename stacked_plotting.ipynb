{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from astropy.timeseries import LombScargle\n",
    "\n",
    "default_settings = {\n",
    "    'font.size': 16,\n",
    "    'axes.linewidth': 0.8,\n",
    "    'xtick.major.size': 3.5,\n",
    "    'xtick.major.width': 1,\n",
    "    'ytick.major.size': 3.5,\n",
    "    'ytick.major.width': 1\n",
    "}\n",
    "\n",
    "\n",
    "initial_settings = {\n",
    "    'font.size': 22,\n",
    "    'axes.linewidth': 1.25,\n",
    "    'xtick.major.size': 5,\n",
    "    'xtick.major.width': 1.25,\n",
    "    'ytick.major.size': 5,\n",
    "    'ytick.major.width': 1.25\n",
    "}\n",
    "plt.rcParams.update(initial_settings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lines = []\n",
    "spec_lines = []\n",
    "#comment out the lines that we don't want to use\n",
    "#pollutant lines\n",
    "p_lines.append((\"MgII_4481\",4481.130,True)) #strong magnesium line\n",
    "\n",
    "p_lines.append((\"CaII_3933\", 3933.663, False)) #only use for MIKE data\n",
    "p_lines.append((\"CaII_4226\",4226.727, True)) #good\n",
    "p_lines.append((\"FeII_4923\",4923.927, False)) #can't use, crosses over with interorder\n",
    "p_lines.append((\"FeII_5018\",5018.440, False))#not there\n",
    "p_lines.append((\"FeII_5169\",5169.033, False)) #this one gives an error when trying to fit it\n",
    "p_lines.append((\"SiII_5041\",5041.024, True)) #don't use this\n",
    "p_lines.append((\"SiII_5055\",5055.984, True)) #This one is good use it\n",
    "p_lines.append((\"SiII_5957\",5957.560, True))\n",
    "p_lines.append((\"SiII_5978\",5978.930, True))\n",
    "p_lines.append((\"SiII_6347\",6347.100, True)) #these two are quite strong in WD1929+012\n",
    "p_lines.append((\"SiII_6371\",6371.360, True)) #\n",
    "p_lines.append((\"MgI_5172\",5172.683, False))\n",
    "p_lines.append((\"MgI_5183\",5183.602, False))\n",
    "\n",
    "p_lines.append((\"MgII_4481_2\",4481.327, False))\n",
    "p_lines.append((\"MgII_4481\",4481.180,False)) #weighted combination of mg_4481 lines\n",
    "\n",
    "p_lines.append((\"MgII_7877\",7877.054, True)) \n",
    "p_lines.append((\"MgII_7896\",7896.366, True)) #definitely not present\n",
    "p_lines.append((\"OI_7771\",7771.944, True)) #definitely not present\n",
    " #hydrogen lines\n",
    "p_lines.append((\"H_4860\",4860.680, False))\n",
    "p_lines.append((\"H_4860_2\",4860.968, True))#This one gives better values\n",
    "p_lines.append((\"H_4860_2\",4860.968, False))#Weighted combo\n",
    "p_lines.append((\"H_4340\",4340.472,True)) #present\n",
    "p_lines.append((\"H_6563\",6562.79 ,True)) #not present in the 2020 spectra?\n",
    "#pick the spectral lines present in this white dwarf\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#stacked plot creation\n",
    "#data = pd.read_csv(\"/data/wdplanetary/omri/Output/resultfiles/WD1929/Voigt_fitting/only_mg_line/snr_cutoff_16.05612842459828/2021-04-21T03:09:52.703/4481.185.txt\", sep='\\t')\n",
    "#data = pd.DataFrame({\"Wavelength\":(gwav),\"Normalized Data\": (gdata/p_result), \"Voigt fit\": (result.best_fit/p_result), \"Time\": t, \"SNR\": snr, \"Depth\": depth, \"RV\": rv, \"Error\": err}) #[t],[snr], [depth], [rv], [err]])\n",
    "\n",
    "for i in p_lines:\n",
    "    line = i[1]\n",
    "    salt_root_dir = '/data/wdplanetary/omri/Output/resultfiles/WD1929/Voigt_fitting/red_lines/corrected_for_pixel/'  # Replace this with the path to your root directory\n",
    "    # Initialize an empty list to store file paths\n",
    "    plot_files = []\n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(salt_root_dir):\n",
    "        # Iterate over each file in the current directory\n",
    "        for file in files:\n",
    "            # Check if the file ends with '4481.185.txt'\n",
    "            if file.endswith(f'{line}.txt'):\n",
    "                # If it does, append the file path to the list\n",
    "                plot_files.append(os.path.join(root, file))\n",
    "    if len(plot_files) == 0:\n",
    "        continue\n",
    "    def extract_time(file_path):\n",
    "        data = pd.read_csv(file_path, sep='\\t')\n",
    "        return data['Time'].values[0]\n",
    "\n",
    "    # Sort the files based on the time\n",
    "    sorted_files = sorted(plot_files, key=extract_time)\n",
    "    print(sorted_files)\n",
    "    n = 0\n",
    "    fig,ax = plt.subplots(figsize=(6, 30),dpi = 200)\n",
    "    for file in sorted_files:\n",
    "\n",
    "        data = pd.read_csv((file), sep='\\t')\n",
    "    #fig,ax = plt.subplots(figsize=(6, 4),dpi = 100)\n",
    "    #data = pd.read_csv(\"/data/wdplanetary/omri/Output/resultfiles/WD1929/Voigt_fitting/red_lines/corrected_for_pixel/2017-07-1123:29:21.148000/5978.93.txt\", sep='\\t')\n",
    "        time = data['Time'].values[0]\n",
    "        wavelength = data['Wavelength'].values\n",
    "        normalized_data = data['Normalized Data'].values\n",
    "        voigt_fit = data['Voigt fit'].values\n",
    "\n",
    "        snr = data['SNR'].values[0]\n",
    "        depth = data['Depth'].values[0]\n",
    "        rv = data['RV'].values[0]\n",
    "        error = data['Error'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "        ax.plot(wavelength, normalized_data  + n/3 , color='black', linewidth=0.5)\n",
    "        ax.plot(wavelength, voigt_fit  + n/3, color='red')\n",
    "        ax.set_xlim(line-10,line+10)\n",
    "        ax.set_xlabel(\"Wavelength (Ã…)\")\n",
    "        ax.set_ylabel(\"Normalized and offset flux\")\n",
    "        x_text = wavelength[-1] + 0.2  # Add an offset for spacing\n",
    "        ax.text(line+6.5, (1.12 + n/3), f\"SNR:{snr:.3g}\" , verticalalignment='center', fontsize = 12)\n",
    "        ax.text(line+1.9, (1.12+ n/3), f\"{time[:10]}\" , verticalalignment='center', fontsize = 12)\n",
    "\n",
    "\n",
    "        n = n+1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#radial velocity calculations\n",
    "\n",
    "times = []\n",
    "rvs = []\n",
    "errors = []\n",
    "snrs = []\n",
    "depths = []\n",
    "lines = []\n",
    "\n",
    "for i in p_lines:\n",
    "    line = i[1]\n",
    "    salt_root_dir = '/data/wdplanetary/omri/Output/resultfiles/WD1929/Voigt_fitting/red_lines/corrected_for_pixel/'  # Replace this with the path to your root directory\n",
    "    # Initialize an empty list to store file paths\n",
    "    plot_files = []\n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(salt_root_dir):\n",
    "        # Iterate over each file in the current directory\n",
    "        for file in files:\n",
    "            # Check if the file ends with '4481.185.txt'\n",
    "            if file.endswith(f'{line}.txt'):\n",
    "                # If it does, append the file path to the list\n",
    "                plot_files.append(os.path.join(root, file))\n",
    "    if len(plot_files) == 0:\n",
    "        continue\n",
    "    def extract_time(file_path):\n",
    "        data = pd.read_csv(file_path, sep='\\t')\n",
    "        return data['Time'].values[0]\n",
    "\n",
    "    # Sort the files based on the time\n",
    "    sorted_files = sorted(plot_files, key=extract_time)\n",
    "    print(sorted_files)\n",
    "    n = 0\n",
    "    for file in sorted_files:\n",
    "        data = pd.read_csv((file), sep='\\t')\n",
    "        time = data['Time'].values[0]\n",
    "        wavelength = data['Wavelength'].values\n",
    "        normalized_data = data['Normalized Data'].values\n",
    "        voigt_fit = data['Voigt fit'].values\n",
    "\n",
    "        snr = data['SNR'].values[0]\n",
    "        depth = data['Depth'].values[0]\n",
    "        rv = data['RV'].values[0]\n",
    "        error = data['Error'].values[0]\n",
    "\n",
    "        rvs.append(rv)\n",
    "        errors.append(error)\n",
    "        times.append(time)\n",
    "        snrs.append(snr)\n",
    "        depths.append(depth)\n",
    "        lines.append(line)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,j,k,l,m,n in zip(times,rvs,errors,snrs,depths,lines):\n",
    "#    print(i,j,k,l,m,n)\n",
    "times_dt = []\n",
    "for i in times:\n",
    "    time_object = Time(i, format='iso', scale='utc')\n",
    "\n",
    "    times_dt.append(time_object.datetime)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'RVS': rvs,\n",
    "    'ERRS': errors,\n",
    "    'TIMES': times_dt,\n",
    "    'SNRS': snrs,\n",
    "    'LINES': lines\n",
    "})\n",
    "\n",
    "# Group by 'Timestamp' and aggregate values and errors\n",
    "grouped = df.groupby('TIMES').agg({'RVS': 'sum', 'ERRS': lambda x: np.sqrt((x**2).sum())})\n",
    "\n",
    "grouped = df.groupby('TIMES').apply(lambda x: np.average(x['RVS'], weights=1/x['ERRS']))\n",
    "grouped_errors = df.groupby('TIMES').apply(lambda x: np.sqrt(np.sum(x['ERRS']**2)))\n",
    "\n",
    "# Create a new DataFrame with combined RV and error values\n",
    "result_df = pd.DataFrame({'TIMES': grouped.index, 'RVS': grouped.values, 'ERRS': grouped_errors.values})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "condition = (result_df['RVS'] < mean - 2) | (result_df['RVS'] > mean + 2)  # Example condition: remove rows where Age is less than 30\n",
    "result_df = result_df[~condition]  # Use ~ to negate the condition\n",
    "result_df['ERRS'] = np.where(result_df['ERRS'] > 7, 7, result_df['ERRS'])\n",
    "\n",
    "result_df[\"RVS\"]= result_df[\"RVS\"].abs()\n",
    "\n",
    "mean = np.mean(result_df[\"RVS\"])\n",
    "stdev = np.std(result_df[\"RVS\"])\n",
    "print(mean,stdev)\n",
    "result_df.to_csv('/data/wdplanetary/omri/Output/resultfiles/SALT_Voigt/reruns/mg4481_for_table.txt', sep='\\t', index=False)\n",
    "print(result_df)\n",
    "#columns = [\"Times\",\"RVS\",\"ERRORS\",\"SNRS\",\"DEPTHS\",\"LINES\"]\n",
    "#all_data = pd.DataFrame([times,rvs,errors,snrs,depths,lines],columns = columns)\n",
    "#print(all_data)\n",
    "\n",
    "#mean = (np.sum((RV[~np.isnan(RV)] * RV_weight[~np.isnan(RV_weight)])) / (np.sum(RV_weight[~np.isnan(RV_weight)])))\n",
    "#mean_error = np.sqrt(np.sum(RV_weight[~np.isnan(RV_weight)] * RV_err[~np.isnan(RV_err)]**2) / np.sum(RV_weight[~np.isnan(RV_weight)])+ v_precision**2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#frequencies = np.linspace(1.95,2.05,3000)\n",
    "t = result_df[\"TIMES\"]\n",
    "t_days = np.array([(time - t[1]).total_seconds() / (24 * 3600) for time in t])\n",
    "\n",
    "mean = np.mean(result_df[\"RVS\"])\n",
    "stdev = np.std(result_df[\"RVS\"]) \n",
    "v = result_df[\"RVS\"] - mean\n",
    "errs = result_df[\"ERRS\"]\n",
    "errs[np.abs(errs) > 5] = 5\n",
    "print(mean)\n",
    "\n",
    "frequencies = np.linspace(0.001,5,30000)\n",
    "powers = LombScargle(t_days, v).power(frequencies)\n",
    "\n",
    " \n",
    "fig, (ax_t, ax_w) = plt.subplots(2, 1, facecolor=\"white\", figsize=(10,12), constrained_layout=True, dpi = 400)\n",
    "\n",
    "ax_t.errorbar(t_days, v, yerr=errs,fmt = '.k',capsize=5,markersize=10,lw = 1)\n",
    "ax_t.fill_between(t_days, -stdev, stdev, color='gray',label = \"1 sigma\", alpha=0.4)\n",
    "ax_t.fill_between(t_days, -3* stdev, 3* stdev, color='gray',label = \"3 sigma\", alpha=0.2)\n",
    "ax_t.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "ax_t.legend()\n",
    "#ax_t.text(np.max(t)/3, 2.5* stdev, f\"RV mean = {mean:.3g} km/s\")\n",
    "ax_t.text(np.max(t_days)/3, 2* stdev, f'sigma = {stdev:.3g} km/s')\n",
    "ax_t.set_xlabel(\"T - Days\")\n",
    "ax_t.set_ylabel(\"Î”RV - km/s\")\n",
    "\"\"\" \n",
    "#insrerting a planet\n",
    "periodtime = np.linspace(np.min(t), np.max(t), 10000) \n",
    "ax_t.plot(periodtime, np.abs(v).max() * np.sin(2*np.pi* 2*periodtime))\n",
    "ax_t.set_xlim(10,50)\n",
    " \"\"\"\n",
    "#plt.title(\"WD1929+012 Radial Velocity variations using Voigt fits - SALT data\")\n",
    "#plt.xticks(rotation=45)\n",
    "#plt.tight_layout()\n",
    "#plt.ylim(-20,20)\n",
    "#plt.xlim(0,112)\n",
    "\n",
    "normalized_powers = powers/(np.max(np.abs(powers)))\n",
    "ax_w.plot(frequencies, normalized_powers )\n",
    "ax_w.set_xlabel('Angular frequency [Periods/days]')\n",
    "ax_w.set_ylabel('Normalized Power')\n",
    "ax_w.tick_params(axis='x')\n",
    "ax_w.tick_params(axis='y')\n",
    "\n",
    "# Identify significant peaks (you can set your own threshold here)\n",
    "threshold = 0.9  # Adjust as needed\n",
    "significant_peak_indices = np.where(normalized_powers >= threshold)[0]\n",
    "print(significant_peak_indices)\n",
    "print(frequencies[1])\n",
    "significant_peaks = np.array(frequencies[significant_peak_indices])\n",
    "\n",
    "# Estimate false alarm rate for each peak\n",
    "false_alarm_rates = []\n",
    "for peak_freq in significant_peaks:\n",
    "    # Use your preferred method to estimate false alarm rate here\n",
    "    # Example: Monte Carlo simulations\n",
    "    num_simulations = 100  # Adjust as needed\n",
    "    peak_heights_simulated = []\n",
    "    for _ in range(num_simulations):\n",
    "        simulated_data = np.random.normal(0, 1, len(t_days))  # Generate random noise\n",
    "        simulated_power = LombScargle(t, simulated_data, errs).power([peak_freq])\n",
    "        peak_heights_simulated.append(simulated_power[0])\n",
    "    false_alarm_rate = np.sum(peak_heights_simulated >= normalized_powers[np.where(frequencies == peak_freq)]) / num_simulations\n",
    "    false_alarm_rates.append(false_alarm_rate)\n",
    "\n",
    "# Print significant peaks and their corresponding false alarm rates\n",
    "print(\"Significant Peaks:\")\n",
    "for i, freq in enumerate(significant_peaks):\n",
    "    print(f\"Frequency: {freq}, False Alarm Rate: {false_alarm_rates[i]}\")\n",
    " \n",
    "os.makedirs(\"/data/wdplanetary/omri/Output/DeltaRV_files/SALT/Self_crosscorr/\", exist_ok=True)\n",
    "#plt.savefig(\"/data/wdplanetary/omri/Output/DeltaRV_files/SALT/Self_crosscorr/firstrun.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mike stacked plot\n",
    "line = 3933.663\n",
    "\n",
    "\n",
    "mike_root_dir = '/data/wdplanetary/omri/Output/resultfiles/WD1929/MIKE_Voigt_fitting/all_lines/'\n",
    "# Initialize an empty list to store file paths\n",
    "plot_files = []\n",
    "# Walk through all directories and subdirectories\n",
    "for root, dirs, files in os.walk(mike_root_dir):\n",
    "    # Iterate over each file in the current directory\n",
    "    for file in files:\n",
    "        # Check if the file ends with '4481.185.txt'\n",
    "        if file.endswith(f'{line}.txt'):\n",
    "            # If it does, append the file path to the list\n",
    "            plot_files.append(os.path.join(root, file))\n",
    "\n",
    "\"\"\" def extract_time(file_path):\n",
    "    data = pd.read_csv(file_path, sep='\\t')\n",
    "    return data['Time'].values[0]\n",
    "# Sort the files based on the time\n",
    "sorted_files = sorted(plot_files, key=extract_time)\n",
    " \"\"\"\n",
    "\n",
    "plot_files \n",
    "n = 0\n",
    "fig,ax = plt.subplots(figsize=(6, 15),dpi = 200)\n",
    "for file in plot_files[1:]:\n",
    "    data = pd.read_csv((file), sep='\\t')\n",
    "    #print(data.to_string(index=False))\n",
    "    time = data['Time'].values\n",
    "    wavelength = data['Wavelength'].values\n",
    "    normalized_data = data['Normalized Data'].values\n",
    "    voigt_fit = data['Voigt fit'].values\n",
    "    \n",
    "    snr = data['SNR'].values[0]\n",
    "    depth = data['Depth'].values[0]\n",
    "    rv = data['RV'].values[0]\n",
    "    error = data['Error'].values[0]\n",
    "    ax.plot(wavelength, normalized_data  + n/2 , color='black', linewidth=0.5)\n",
    "    ax.plot(wavelength, voigt_fit  + n/2, color='red')\n",
    "    ax.set_xlim(line-10,line+10)\n",
    "    ax.set_xlabel(\"Wavelength (Ã…)\")\n",
    "    ax.set_ylabel(\"Normalized and offset flux\")\n",
    "    x_text = wavelength[-1] + 0.2  # Add an offset for spacing\n",
    "    ax.text(line+6.5, (1.2 + n/2), f\"SNR:{snr:.3g}\" , verticalalignment='center', fontsize = 12)\n",
    "    ax.text(line+1.9, (1.1+ n/2), f\"{time[1]}\" , verticalalignment='center', fontsize = 12)\n",
    "    n = n+1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
